{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General\n",
    " \n",
    "\n",
    "Your task is to visualize labour / employment data ((https://www150.statcan.gc.ca/n1/daily-quotidien/190308/dq190308a-eng.htm) for Canada by province and industry for the last 5 years which should be pivotable by demographic (age, sex, ethnicity and industry / sector).\n",
    "\n",
    "Use open skills data and job titles using this link  and visualize a mashup correlating skills and jobs to industry and employment and provide a sample for evaluation.\n",
    "\n",
    "Suggest in detail, how you would train these two data sets over time and what machine learning algorithm you would use to make the data \"smarter\" over time.\n",
    "\n",
    " \n",
    "\n",
    "Submission Process: \n",
    "Please begin by creating a Project. Your Project should contain both the final output and a Github link to your source code. Please name all of your files and documents using the following convention:\n",
    "John_Smith_MachineLearning_Nameofyourfile. Once it is completed, you will be able to submit it here to the Work Challenge. \n",
    "\n",
    "\n",
    "Evaluation Criteria: \n",
    "25% on your approach to tackling the problem and the steps you took to get to your solution and final deliverable\n",
    "25% on how well you used various tools & processes to tackle the challenge\n",
    "50% on the final solution and output of your challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "from pivottablejs import pivot_ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#reading in the labour DATA\n",
    "csv_path = r'C:\\Users\\Prateek\\Desktop\\prepr\\Prateek_Asthana_MachineLearning_Labour_Data_Set.csv'\n",
    "labour_df = pd.read_csv(csv_path)\n",
    "\n",
    "#Filling 0 for empty values in coloumn VALUE\n",
    "labour_df.VALUE.fillna(value=0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500\"\n",
       "            src=\"pivottablejs.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x206f7561518>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_ui(labour_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in the job skills DATA\n",
    "csv_path = r'C:\\Users\\Prateek\\Desktop\\prepr\\Prateek_Asthana_MachineLearning_job_skills.csv'\n",
    "job_skills_df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500\"\n",
       "            src=\"pivottablejs.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x206f7a31a58>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_ui(job_skills_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in the correlation DATA\n",
    "csv_path = r'C:\\Users\\Prateek\\Desktop\\prepr\\Prateek_Asthana_MachineLearning_correlations.csv'\n",
    "correlation_df = pd.read_csv(csv_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500\"\n",
       "            src=\"pivottablejs.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x206f7a31d68>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_ui(correlation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suggest in detail, how you would train these two data sets over time and what machine learning algorithm you would use to make the data \"smarter\" over time.\n",
    "\n",
    "I would use the correlation dataset to determine how many unemployed people we will have in future years. I would use LSTM(Long Short Term Memory) algorithm because i would like the dataset to be in a feedback loop so it increases the lifespan of the model and also the accuracy because LSTM has feedback connections. I would like the correlation dataset to be created automatically, and increase amount of fields so it can also calculate employment rate. With employment rate and unemplyment rate being calculated for future years we can take further steps to improve the model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
